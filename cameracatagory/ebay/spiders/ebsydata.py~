# -*- coding: utf-8 -*-
from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import Selector
from data.items import DataItem
import re
import scrapy


class ebaydataSpider(CrawlSpider):
    download_delay = 1
    name="camerasales"
    allowed_domains=['ebay.com']
    start_urls=['http://stores.ebay.com/wanlanlan3599?_trksid=p2047675.l2563']
    rules = [Rule(SgmlLinkExtractor(restrict_xpaths=('//a[@class="gspr next"]'))),# xpath is right and vist the next page
            Rule(SgmlLinkExtractor(restrict_xpaths=('//a[@class="vip"]'))), # xpath is OK. vist the page in given catagory
            Rule(SgmlLinkExtractor(restrict_xpaths=('//div[@class="si-ss-eu"]/a'))),#xpath is right.vist the store from the listing.
            Rule(SgmlLinkExtractor(restrict_xpaths=('//td[@class="gspr nextBtn"]/a'))),#vist the next page in the store
            Rule(SgmlLinkExtractor(restrict_xpaths=('//td[@class="next"]/a'))),  #vist the next page in the store
            Rule(SgmlLinkExtractor(restrict_xpaths=('//a[@class="gspr nextBtn"]'))),
            Rule(SgmlLinkExtractor(restrict_xpaths=('//a[@class="vi-url"]')),'myparse')
            Rule(SgmlLinkExtractor(restrict_xpaths=('//td[@class="next"]/a'))),#vist the next page in the store
            Rule(SgmlLinkExtractor(restrict_xpaths=('//div[@class="vi-url"]/a')),'myparse'),#vist listings in the store
            Rule(SgmlLinkExtractor(restrict_xpaths=('//div[@class="ttl"]/a')),'myparse'),#vist listings in the store
            Rule(SgmlLinkExtractor(restrict_xpaths=('//div[@class="ttl g-std"]/a')),'myparse') #vist listings in the store
            ]  
             
     
    def myparse(self,response):
        for url in response.xpath('//a[contains(text(),"sold")]/@href').extract():
            yield scrapy.Request(url,callback=self.mp)     
    def mp(self,res):
       lis=res.xpath('//tr[contains(@bgcolor,"#f")]')       
       i=0
       for l in lis:                       
          items=DataItem()
          reg0='[0-9]{12}'
          pr0=re.compile(reg0)
          t0=re.findall(pr0,res.url)
          items["itemnumber"]=t0
          td=l.xpath('td[@class="contentValueFont"]/text()').extract()
          #reg='[0-9]*\.[0-9]*'
          #pr=re.compile(reg)
          #t= re.findall(pr,td[0])
          #item['price']=t[0]
          #for s in td:
          tempprice=td[0]
          items['price']=tempprice[4:]
          items['quantity']=td[1]
          def func(s):
              di={'Jan':'01','Feb':'02',
                  'Mar':'03','Apr':'04',
                  'May':'05','Jun':'06',
                  'Jul':'07','Aug':'08',
                  'Sep':'09','Otc':'10',
                  'Nov':'11','Dec':'12'
                  }
              date_str=s.split(' ')[0]
              li=date_str.split('-')
              li[0]=di[li[0]]
              lidate=[]
              lidate.append(li[2])
              lidate.append(li[0])
              lidate.append(li[1])
              out=str('-'.join(lidate))
              return out 
          tm=func(td[2])
          items['tim']=tm
          yield items     
       
