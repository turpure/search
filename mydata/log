2015-05-14 09:39:19+0000 [scrapy] INFO: Scrapy 0.25.1 started (bot: data)
2015-05-14 09:39:19+0000 [scrapy] INFO: Optional features available: ssl, http11
2015-05-14 09:39:19+0000 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'data.spiders', 'SPIDER_MODULES': ['data.spiders'], 'LOG_FILE': 'log', 'BOT_NAME': 'data'}
2015-05-14 09:39:19+0000 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, LogStats, SpiderState
2015-05-14 09:39:19+0000 [twisted] ERROR: Unhandled error in Deferred:
2015-05-14 09:39:19+0000 [twisted] ERROR: Unhandled Error
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/cmdline.py", line 150, in _run_command
    cmd.run(args, opts)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/commands/crawl.py", line 57, in run
    self.crawler_process.crawl(spname, **opts.spargs)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/crawler.py", line 152, in crawl
    d = crawler.crawl(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1253, in unwindGenerator
    return _inlineCallbacks(None, gen, Deferred())
--- <exception caught here> ---
  File "/usr/local/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1107, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/crawler.py", line 70, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/crawler.py", line 82, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/core/engine.py", line 66, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/core/downloader/__init__.py", line 69, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/middleware.py", line 56, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/middleware.py", line 32, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python2.7/dist-packages/Scrapy-0.25.1-py2.7.egg/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/lib/python2.7/importlib/__init__.py", line 37, in import_module
    __import__(name)
exceptions.ImportError: No module named CSDNBlogCrawlSpider.spiders.rotate_useragent

2015-05-14 09:41:17+0000 [scrapy] INFO: Scrapy 0.25.1 started (bot: data)
2015-05-14 09:41:17+0000 [scrapy] INFO: Optional features available: ssl, http11
2015-05-14 09:41:17+0000 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'data.spiders', 'SPIDER_MODULES': ['data.spiders'], 'LOG_FILE': 'log', 'BOT_NAME': 'data'}
2015-05-14 09:41:17+0000 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, CoreStats, LogStats, SpiderState
2015-05-14 09:41:18+0000 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RotateUserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-05-14 09:41:18+0000 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-05-14 09:41:18+0000 [scrapy] INFO: Enabled item pipelines: 
2015-05-14 09:41:18+0000 [scrapy] INFO: Spider opened
2015-05-14 09:41:18+0000 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-05-14 09:41:18+0000 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023
2015-05-14 09:41:18+0000 [py.warnings] WARNING: /home/james/Downloads/mydata/data/spiders/rotate_useragent.py:18: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg('Current UserAgent: '+ua, level='INFO')

2015-05-14 09:41:18+0000 [scrapy] ERROR: Error downloading <GET http://stores.ebay.com/wanlanlan3599?_trksid=p2047675.l2563>
2015-05-14 09:41:18+0000 [scrapy] INFO: Closing spider (finished)
2015-05-14 09:41:18+0000 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/exceptions.TypeError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2015, 5, 14, 1, 41, 18, 50386),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2015, 5, 14, 1, 41, 18, 44046)}
2015-05-14 09:41:18+0000 [scrapy] INFO: Spider closed (finished)
